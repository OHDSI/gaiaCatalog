###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> XAI4 {\n  provider openai-generic\n  options {\n    model grok-4-fast\n    base_url \"https://api.x.ai/v1\"\n    api_key env.XAI_API_KEY\n  }\n}\n\nclient<llm> XAI {\n  provider openai-generic\n  options {\n    model grok-3-mini\n    base_url \"https://api.x.ai/v1\"\n    api_key env.XAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.86.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "rag.baml": "\nclass ResponseWithCitations {\n  question string\n  answer string\n  citations Citation[]\n}\n\nclass Citation {\n    id string\n    citationText string\n}\n\n\n//   detailed summary of the relevant text in complete sentences within the citations section.\n // \"CustomGPT4o\"\n\nfunction RAGWithCitations(question: string, context: string) -> ResponseWithCitations {\n  client \"XAI4\"\n  prompt #\"\n   Provide a comprehensive and cohesive answer to the question in full sentences, synthesizing information from all relevant context chunks provided.\n\n   Ensure the response is clear, detailed, and avoids redundancy by combining related information from multiple chunks into a unified narrative.\n\n   If the context contains conflicting information, acknowledge and clarify the differences.\n\n   If the answer includes specific details from the context, cite each source by including its urn ID and a\n   the full text of the provided citation.\n\n   Reference all citations used in the response by their ID.\n\n    If the information to fully answer the question is  not provided in the context, clearly state what is missing and\n    provide a partial answer based on available information. Do not make up or assume information beyond what is provided.\n\nQUESTION: {{ question }}\nRELEVANT CONTEXT: {{ context }}\n\n{{ ctx.output_format }}\n\n  \"#\n}\n",
}

def get_baml_files():
    return file_map